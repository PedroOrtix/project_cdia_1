# AnÃ¡lisis Comparativo de ResNet: Impacto del NÃºmero de Bloques en el Aprendizaje

## ğŸ“‹ DescripciÃ³n
Este proyecto investiga cÃ³mo el nÃºmero de bloques residuales en una arquitectura ResNet afecta su capacidad de aprendizaje y rendimiento. Se realizan experimentos comparativos con diferentes configuraciones de ResNet para analizar la relaciÃ³n entre la profundidad de la red y su efectividad.

## ğŸ¯ Objetivos
- Comparar el rendimiento de ResNet con diferentes nÃºmeros de bloques residuales
- Analizar la velocidad de convergencia en el entrenamiento
- Evaluar la precisiÃ³n final alcanzada por cada configuraciÃ³n
- Identificar la relaciÃ³n Ã³ptima entre profundidad y rendimiento

## ğŸ› ï¸ Requisitos
```python
pytorch-lightning>=2.0.0
torch>=2.0.0
torchvision>=0.15.0
datasets>=2.0.0
transformers>=4.0.0
tensorboard>=2.0.0
pillow>=8.0.0
torchmetrics>=0.11.0
```

## ğŸ“ Estructura del Proyecto
```
project/
â”œâ”€â”€ lightning_modules/       # MÃ³dulos de PyTorch Lightning
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ restnet_module.py    # ImplementaciÃ³n de ResNet
â”œâ”€â”€ models/                  # Modelos guardados
â”‚   ï¿½ï¿½ï¿½â”€â”€ checkpoints/        # Checkpoints durante el entrenamiento
â”œâ”€â”€ results/                # Resultados y mÃ©tricas
â”‚   â””â”€â”€ beans/             # Resultados especÃ­ficos del dataset de frijoles
â”œâ”€â”€ scripts/                # Scripts de entrenamiento
â”‚   â”œâ”€â”€ fine_tuning_function.py
â”‚   â””â”€â”€ train_beans.py
â”œâ”€â”€ utils/                  # Utilidades
â”‚   â””â”€â”€ data_loader.py      # Funciones de carga de datos
â””â”€â”€ requirements.txt        # Dependencias del proyecto
```

## ğŸš€ CaracterÃ­sticas Principales

### ResNet Transfer Learning
- Modelo base: ResNet18 pre-entrenado en ImageNet
- Capacidad de congelar bloques selectivamente para transfer learning
- MÃ©tricas implementadas:
  - Accuracy (entrenamiento y validaciÃ³n)
  - PÃ©rdida (entrenamiento y validaciÃ³n)
- OptimizaciÃ³n:
  - Optimizador: AdamW
  - Learning Rate: 1e-4

### Dataset
- Dataset: Beans de Hugging Face (AI-Lab-Makerere/beans)
- 3 clases diferentes de plantas de frijol
- Transformaciones de datos:
  - Redimensionamiento a 224x224
  - NormalizaciÃ³n con medias y desviaciones estÃ¡ndar de ImageNet

## ğŸ’» Uso

### InstalaciÃ³n
```bash
# Clonar el repositorio
git clone [URL_DEL_REPOSITORIO]
cd project

# Instalar dependencias
pip install -r requirements.txt
```

### Entrenamiento
```bash
# Entrenar el modelo con configuraciÃ³n por defecto
python scripts/train_beans.py

# Los parÃ¡metros configurables incluyen:
- num_classes: NÃºmero de clases (default: 3)
- batch_size: TamaÃ±o del batch (default: 16)
- learning_rate: Tasa de aprendizaje (default: 1e-4)
- max_epochs: NÃºmero mÃ¡ximo de Ã©pocas (default: 20)
- freeze_blocks: NÃºmero de bloques a congelar (default: 4)
- num_workers: NÃºmero de workers para data loading (default: 4)
```

## ğŸ“Š CaracterÃ­sticas del Entrenamiento

### ConfiguraciÃ³n del Modelo
- **Arquitectura Base**: ResNet18
- **Transfer Learning**: 
  - Pesos pre-entrenados de ImageNet
  - 4 bloques congelados por defecto
  - Capa final adaptada a 3 clases

### OptimizaciÃ³n
- **Optimizador**: AdamW
- **Learning Rate**: 1e-4
- **Batch Size**: 16
- **Ã‰pocas MÃ¡ximas**: 20

### Resultados
Los resultados del entrenamiento se guardan en:
- Directorio: `results/beans/`
- Formato: Archivos JSON con mÃ©tricas y configuraciones
- Timestamp: Cada experimento se guarda con marca de tiempo Ãºnica

## ğŸ“ Licencia
Este proyecto estÃ¡ bajo la licencia [ESPECIFICAR_LICENCIA].